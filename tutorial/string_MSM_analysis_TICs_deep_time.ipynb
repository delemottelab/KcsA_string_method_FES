{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32867ee4-ea45-4aa9-b192-176b0801c41c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# String Method Analysis Markov-State-Models\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b1c221-b47d-4484-9125-6eac0a75a249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "logging.getLogger(\"stringmethod\").setLevel(logging.ERROR)\n",
    "sys.path.append(\"../string-method-gmxapi/\")\n",
    "import src.analysis.string_tica_msm as my_msm\n",
    "import src.analysis.plotting as my_plot\n",
    "import src.analysis.cvs as my_cvs\n",
    "from src.analysis.utils import natural_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a829a2-f0ff-42c3-a3be-ec5f9923d705",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7af371-cecb-41f7-b46d-77e31ddb70cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0249545e-242c-4b87-b632-6268e4fe55aa",
   "metadata": {},
   "source": [
    "This notebook needs to run in the string simulation folder, this cell will get you there. You also set up a path for writing the figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce510b6f-1e1c-416f-b30b-6bbda63671a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_sim = \"LB-CHARMM/\"\n",
    "simulation_directory = f\"/data/sperez/Projects/string_sims/data/raw/{name_sim}/\"\n",
    "os.chdir(simulation_directory)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fb2261-372f-460c-a3db-c958e6114a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cv.pkl\", \"rb\") as file:\n",
    "    cvs, ndx_groups = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fadba22-5407-4d9c-a90c-b3ed0888f37b",
   "metadata": {},
   "source": [
    "The `load_swarm_data` function will load the swarm data in the `cv_coordinates`. If you set `extract=True` it will read the data from the swarm files. If you have done this previously you can set `extract=False` so the function just reads `postprocessing/cv_coordinates.npy`. `first_iteration` can be used to exclude initial swarms as equilibration and `last_iteration` can be done to exclude some iterations for example if you want to estimate the FES convergence by comparing blocks of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ddb40f-95ec-41d2-a7ec-5df6906f1e21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv_coordinates = my_msm.load_swarm_data(\n",
    "    extract=True, first_iteration=100, #last_iteration=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8988064-940c-460d-ab30-9e257b960dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = natural_sort(glob(\"./strings/string[0-9]*txt\"))\n",
    "strings = np.array([np.loadtxt(file).T for file in files])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afec4c2e-b848-407d-a946-79850a81368f",
   "metadata": {},
   "source": [
    "## Dimensionality reduction with TICA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba17c84c-4f42-4e4f-a944-4ad1b6226251",
   "metadata": {},
   "source": [
    "The following cell computes the tica projection of the string cvs and discards the tics that have the lowest kinetic variance. This reduces the cvs space to a lower dimensional space that is adapted to the kinetic variance. You can use the drop keyword to drop certain cvs that are not well converged in the string simulation or that change very little from the beggining to the end of the string. The best case scenario is that `drop=[]` just works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04164fe3-93ab-4228-a4c4-467efe9ecbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tica = my_msm.cvs_to_tica(cv_coordinates, drop=[20, 21, 22, 23, 32, 33, 34, 35])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e0b54f-a57e-4cf9-8f7d-15a9123e2984",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fde8c4f-47c5-4c5f-89d9-1ec645366c6b",
   "metadata": {},
   "source": [
    "The next cell plots the \"vamp score\" of using `n_clustercenters` to make an MSM. You should find that at some point the vamp score saturates. Choose the minimum number of clusters that gives you the saturated vamp score as the value of k for the next steps. This might take a little while.`n_jobs` refers to the number of parallel processes used. `scores` gives you the vamp scores in case you want to save them or use them some other way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37e6526-2107-4133-83ae-47fe3c85c4d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_clustercenters = [5, 10, 30, 50, 75, 100, 200, 500][::-1]\n",
    "fig, ax, _ = my_msm.get_vamp_vs_k(n_clustercenters, tica, n_jobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eab2eb-06eb-4b71-a75f-7d0aa8221de6",
   "metadata": {},
   "source": [
    "If the calculation fails, there is something wrong with your MSM. Either you have too little transitions or there too many cvs in tica to have all the states well connected. Solutions:\n",
    "+ Reduce the maximum number of clusters (drop 200 and 500) of `n_clustercenters` and see if you get a saturated curve.\n",
    "+ Reduce the number of cvs that went into your TICA calculation.\n",
    "+ Do more iterations of the string method.\n",
    "+ Use the `allow_failed_msms=True` but be carefull :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819a82df-a07a-4391-ba1e-a320c10b7a05",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MSM Deeptime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be88b3d8-10e5-4e85-ad92-0e107eb240c2",
   "metadata": {},
   "source": [
    "Choose the number of clusters, `k`, for the clustering from the previous calculation. Also change n_proc to however many processors you can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7701fadd-4a0e-49a9-a6e0-258010e1e54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 100\n",
    "clusters = my_msm.k_means_cluster(\n",
    "    tica, k, stride=1, max_iter=500, n_jobs=4, seed=28101990\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7fcd39-9913-4f1c-8740-2615f430bca6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "msm, weights = my_msm.get_msm(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3673fc24-a1dd-4577-9ed1-70d614e09bd7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CVs for projection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc2733a-eb34-483c-874c-905e45d9b559",
   "metadata": {},
   "source": [
    "Make a `cv_proj` numpy array with shape (n_iteration * n_swarms_iterations, n_frames_per_iter, 2). n_frames_per_iter is usally 2 since you only record the value of the cvs at the begining and end of the swarm. The last dimesions are the cvs on which you would like to project your FES using the weights obtained from the msm. The FES is then the negative log of a *weighted* histogram of the projection cvs using the weights from the msm. The projection cvs can be anything that you can calculate for a structure, not necessarily the cvs of the string. In the example bellow it is the mean of two cvs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7758f72-9e44-4770-a5b4-1337b5d1ae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_proj = np.concatenate(\n",
    "    [\n",
    "        np.mean([cv_coordinates[:, :, 0:1], cv_coordinates[:, :, 1:2]], axis=0),\n",
    "        np.mean([cv_coordinates[:, :, 10:11], cv_coordinates[:, :, 11:12]], axis=0),\n",
    "    ],\n",
    "    axis=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa20877-6de5-4e29-8d35-66b257239baf",
   "metadata": {},
   "source": [
    "## Project FES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec818b9-9192-42f6-afd2-06cdcd14fe09",
   "metadata": {},
   "source": [
    "Do the projection and take log. You have to choose a bandwidth for the [KDE](https://en.wikipedia.org/wiki/Kernel_density_estimation) of the histogram. It should be big enough to reduce noise but not so big to remove features. If you give `None`\n",
    "\n",
    "**Warning** The actual bandwith used by the algorithm is the covariance matrix of the data (since the gaussians are multidimensional) times the bandwidth. So if you change the data the spread of the KDE gaussians changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf589f3f-60c3-4237-8da1-7b5f4b5a5a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bandwidth = 0.05\n",
    "p_of_cv, extent = my_msm.get_kde(cv_proj, weights, bandwidth)\n",
    "F0 = -np.log(p_of_cv)\n",
    "F = F0 - F0.min()\n",
    "F[F > 40] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bfa74c-f72f-4919-a8da-29055957afd4",
   "metadata": {},
   "source": [
    "## Plot FES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed42a66-3599-411b-af26-88990691e49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_max = 25\n",
    "fig, ax = my_plot.plot_2D_heatmap(\n",
    "    F,\n",
    "    extent,\n",
    "    f_max=f_max,\n",
    "    cbar_label=\"Free Energy (kT)\",\n",
    "    xlabel=\"SF (nm)\",\n",
    "    ylabel=\"IG (nm)\",\n",
    ")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4af9d6-c73a-4b44-b786-a9ec31571f46",
   "metadata": {},
   "source": [
    "## Bootstrap to get error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaeb808-1306-4705-9bec-e225d9ecf993",
   "metadata": {},
   "source": [
    "The problem with calculating errors in MD is that most statistical techniques for this rely on the data being uncorrelated. MD data is most of the time highly correlated due to the proximity in time and starting structure. Correlated data generates artificially low error estimates. \n",
    "\n",
    "For this reason we use blocking. In our case we will use blocking+bootstrapping. This is very well explained in this [very usefull video](https://www.youtube.com/watch?v=gHXXGYIgasE&t=1854s) by prof. Giovanni Bussi.\n",
    "\n",
    "The uncertainty is calculated as half of the interval containing 95% of the probability of the distribution of histograms generated in the bootstraps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62641e3-4288-47b8-95f3-04a15f1b1ecc",
   "metadata": {},
   "source": [
    "This part is probably going to be slow! Maybe it will go over night. It is actually doing len(blocks) * n_boot msms! The good things is that once you have figured out for your system (and similar systems) what is a reasonable number of blocks then you can just do `blocks=[my_reasonable_number_blocks]`. 100-150 iterations seems reasonable in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a0ecf4-1e8b-4588-8187-b13ef8d02e46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add n_jobs\n",
    "n_boot = 100\n",
    "blocks = [2, 4, 8, 16, 32]\n",
    "errors = my_msm.get_error(\n",
    "    cv_proj,\n",
    "    clusters,\n",
    "    extent,\n",
    "    n_boot=n_boot,\n",
    "    bandwidth=0.05,\n",
    "    nbin=55,\n",
    "    n_jobs=4,\n",
    "    blocks=blocks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e88e57-20c0-4846-a2ac-a5806add16f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "errors[:, ~np.isfinite(F)] = np.nan\n",
    "label = f\"n_boot={n_boot}\"\n",
    "mean = np.nanmean(errors, axis=(1, 2))\n",
    "std_err = np.nanstd(errors, axis=(1, 2)) / np.sqrt(errors.shape[0])\n",
    "ax.plot(np.array(blocks), mean, marker=\"o\", label=label)\n",
    "ax.fill_between(np.array(blocks), mean + std_err, mean - std_err, alpha=0.3)\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Number of blocks\", size=15)\n",
    "ax.set_ylabel(\"FES error (kT)\", size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdea64c-85e5-475a-869b-53ab8c087536",
   "metadata": {},
   "source": [
    "From the previous plot you can see which is the adequate number of blocks that low but still gives you the plateauing (or highest) error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38416821-c227-4a2f-8fd6-eeb4668198b0",
   "metadata": {},
   "source": [
    "Choose the number of blocks that gives you a high error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9718d087-a494-4ab4-8cd9-6b212685982b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "number_blocks = 16\n",
    "f_max = 20\n",
    "e_max = None\n",
    "\n",
    "e = errors[blocks.index(number_blocks)].copy()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10 * 2, 7), sharex=True, sharey=True)\n",
    "_ = my_plot.plot_2D_heatmap(\n",
    "    F,\n",
    "    extent,\n",
    "    f_max=f_max,\n",
    "    cbar_label=\"Free Energy (kT)\",\n",
    "    xlabel=\"SF (nm)\",\n",
    "    ylabel=\"IG (nm)\",\n",
    "    fig=fig,\n",
    "    ax=ax[0],\n",
    ")\n",
    "_ = my_plot.plot_2D_heatmap(\n",
    "    e,\n",
    "    extent,\n",
    "    f_max=e_max,\n",
    "    cbar_label=\"FES Uncertainty (kT)\",\n",
    "    xlabel=\"SF (nm)\",\n",
    "    cmap=plt.cm.viridis_r,\n",
    "    fig=fig,\n",
    "    ax=ax[1],\n",
    ")\n",
    "ax[1].set_title(\"Bootstrap Error (95%)\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c71282-a9d8-48f5-9317-9ed6bdad982e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Path CVs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3db9569-97c7-427f-b85f-55ca12e4c9ef",
   "metadata": {},
   "source": [
    "Path cvs are calculated based on the article by [Branduardi et al.](https://aip.scitation.org/doi/pdf/10.1063/1.2432340). We assign two cvs to the path, `s_path` as a cv measuring the position of the trajectory along the path and `z_path` the position of the trajectory perpendicular to the path.\n",
    "\n",
    "Define as the transition path as the average of the last `av_last_n_it` of the strings. Obtain a reasonable guess of the parameter lambda according to the heuristics of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b60e192-2233-4c84-91ff-8e0bd951bdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_strings = strings.shape[0]\n",
    "av_last_n_it = 25\n",
    "path = np.mean(strings[n_strings - av_last_n_it :, :, :], axis=0)\n",
    "lam = my_cvs.get_path_lambda(path)\n",
    "print(f\"Lambda value for path {lam:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353af731-16ae-481d-a980-306ac0cf0196",
   "metadata": {},
   "source": [
    "Let's see if the lambda gives a well behaved path cv. The progress variable (s) should be increasing in the path itself and the distance to path variable (z) be low and constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a3e9fd-93b8-466b-b27c-e627cd9693c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Representation of Path CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20d680b-a2e1-4316-8a23-9e4bc32a9f8c",
   "metadata": {},
   "source": [
    "### Load data and calculate path cvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019aa102-31d3-4b39-ab94-9b77b3341dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_of_path = []\n",
    "for p in path.T:\n",
    "    cv_of_path.append(my_cvs.cvs_to_path(p, path=path, lam=lam))\n",
    "cv_of_path = np.array(cv_of_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec1386d-c359-4867-afb8-e83b89bf66e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs_path = []\n",
    "for i in range(cv_coordinates.shape[0]):\n",
    "    cvs_path.append([])\n",
    "    for j in range(cv_coordinates.shape[1]):\n",
    "        cvs_path[i].append(\n",
    "            my_cvs.cvs_to_path(cv_coordinates[i, j, :], path=path, lam=lam)\n",
    "        )\n",
    "cvs_path = np.array(cvs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7865268-478a-4c68-9158-f843dde6f6b1",
   "metadata": {},
   "source": [
    "### Path CV on final string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8468d28f-fb8d-4431-962a-464eb8e00bfe",
   "metadata": {},
   "source": [
    "If the path and lambda you have calculated is OK: \n",
    "+ `S` should increase with bead number in an approximate range 0 to 1. \n",
    "+ `Z` should be small and oscillating about some constant value. (We don't care too much about z anyway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3183419-0305-4994-a106-9e37af66c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10 * 2, 7))\n",
    "ax[0].plot(cv_of_path[:, 0], marker=\"o\")\n",
    "ax[1].plot(cv_of_path[:, 1], marker=\"o\")\n",
    "ax[0].set_xlabel(\"bead number\")\n",
    "ax[0].set_ylabel(\"S\")\n",
    "ax[1].set_xlabel(\"bead number\")\n",
    "ax[1].set_ylabel(\"Z\")\n",
    "ax[0].set_title(f\"Path-variable {lam = :.2f}\")\n",
    "ax[1].set_title(f\"Path-variable {lam = :.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d5fe8-2c23-4ab0-b4fb-ddde8d1e89bb",
   "metadata": {},
   "source": [
    "### Path CV projected on IG vs SF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246af758-2531-4c79-9359-b6de8b154a11",
   "metadata": {},
   "source": [
    "Check how the path variables project onto the canonical inactivation 2CV FES\n",
    "\n",
    "The projection code is general, you can project any property provided it is in a numpy array with the right shape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057acd18-f5ed-4d62-ae6e-448775cb5e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bandwidth = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b656d2f-a5f7-4947-884c-421b94d08e10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s_of_cv, extent = my_msm.project_property_on_cv_kde(\n",
    "    cv_proj, weights=weights, proper=cvs_path[:, :, 0:1], bandwidth=bandwidth\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9379b01d-3527-4499-bac3-9e8be4377b7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z_of_cv, extent = my_msm.project_property_on_cv_kde(\n",
    "    cv_proj, weights=weights, proper=cvs_path[:, :, 1:2], bandwidth=bandwidth\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05248f89-e038-4711-93f1-4239ab643487",
   "metadata": {},
   "source": [
    "The z graph is not really interesting and I don't interpret it much.\n",
    "\n",
    "The s projection graph (left) is very important. If your definition of the path and lambda are correct the color should go from low to high as the system moves from reactants to products (or vice versa). This is a way of knowing if you are capturing the right physics with the `s_path` cv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45382eb-94af-4766-b469-e0161860bdd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10 * 2, 7), sharex=True, sharey=True)\n",
    "_ = my_plot.plot_2D_heatmap(\n",
    "    s_of_cv,\n",
    "    extent,\n",
    "    cbar_label=\"s[path]\",\n",
    "    xlabel=\"SF (nm)\",\n",
    "    ylabel=\"IG (nm)\",\n",
    "    f_min=0,\n",
    "    f_max=1,\n",
    "    fig=fig,\n",
    "    cmap=plt.cm.Spectral,\n",
    "    ax=ax[0],\n",
    "    n_colors=200,\n",
    "    c_density=F,\n",
    "    c_min=0,\n",
    "    c_max=20,\n",
    "    c_color=\"k\",\n",
    ")\n",
    "ax[0].contour(F, levels=20, extent=extent, vmin=0, vmax=20, colors=\"k\")\n",
    "ax[0].grid(None)\n",
    "_ = my_plot.plot_2D_heatmap(\n",
    "    z_of_cv,\n",
    "    extent,\n",
    "    cbar_label=\"z[path]\",\n",
    "    xlabel=\"SF (nm)\",\n",
    "    cmap=plt.cm.magma,\n",
    "    f_min=0,\n",
    "    f_max=0.15,\n",
    "    fig=fig,\n",
    "    ax=ax[1],\n",
    "    n_colors=200,\n",
    "    c_density=F,\n",
    "    c_min=0,\n",
    "    c_max=20,\n",
    "    c_color=\"w\",\n",
    ")\n",
    "ax[1].contour(F, levels=20, extent=extent, vmin=0, vmax=20, colors=\"w\")\n",
    "ax[1].grid(None)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b68191-f34f-4302-8872-0a150d905aad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calculate FES projected on path CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5020258e-babc-4b98-a8c0-84188fe31e35",
   "metadata": {},
   "source": [
    "Calculate FES preliminarily, for example to optimize `bandwidth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f42406-c287-4dc7-a34b-825eed5c6adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_path = cvs_path[:, :, 0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e53b634-85ac-4392-88ef-777562d9c34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bandwidth = 0.25\n",
    "nbins = 100\n",
    "p_of_cv, extent = my_msm.get_kde(s_path, weights, bandwidth, nbins=nbins)\n",
    "F0 = -np.log(p_of_cv)\n",
    "F = F0 - F0.min()\n",
    "F[F > 40] = np.nan\n",
    "s = np.linspace(extent[0], extent[1], nbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c98ab79-5319-48ae-b0fe-722a9475efe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 7))\n",
    "ax.plot(s, F, marker=\".\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"s[path]\", size=15)\n",
    "ax.set_ylabel(\"F (kT)\", size=15)\n",
    "ax.set_ylim([0, 20])\n",
    "ax.set_xlim([0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae58af8a-feb9-4cf1-9ba8-d7dd44feae5d",
   "metadata": {},
   "source": [
    "## Calculate errors FES s-path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443cfd7b-3722-4f83-96cd-169e55969fdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import src.analysis as spc\n",
    "\n",
    "blocks = [2, 4, 8, 16, 32]\n",
    "n_blocks = len(blocks)\n",
    "n_boot = 100\n",
    "errors = spc.get_error(\n",
    "    s_path,\n",
    "    clusters,\n",
    "    extent,\n",
    "    n_boot=n_boot,\n",
    "    bandwidth=bandwidth,\n",
    "    nbin=nbins,\n",
    "    blocks=blocks,\n",
    "    seed=28101990,\n",
    "    n_jobs=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3e9631-0f64-4b01-8682-c961856956f7",
   "metadata": {},
   "source": [
    "Choose the number of blocks that gives you a high error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2d503e-dfb7-4dfa-b59b-33735550b301",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "errors[:, ~np.isfinite(F)] = np.nan\n",
    "label = f\"n_boot={n_boot}\"\n",
    "mean = np.nanmean(errors, axis=1)\n",
    "std_err = np.nanstd(errors, axis=1) / np.sqrt(errors.shape[0])\n",
    "ax.plot(np.array(blocks), mean, marker=\"o\", label=label)\n",
    "ax.fill_between(np.array(blocks), mean + std_err, mean - std_err, alpha=0.3)\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Number of blocks\", size=15)\n",
    "ax.set_ylabel(\"FES error (kT)\", size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7cf36c-84d0-45de-beef-ea1ad36b28ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "error_block = 8\n",
    "n_blocks = len(blocks)\n",
    "s = np.linspace(extent[0], extent[1], nbins)\n",
    "error = errors[blocks.index(error_block), :]\n",
    "ax.fill_between(s, F + error, F - error, alpha=0.3)\n",
    "ax.plot(s, F, label=f\"{n_boot=}\", marker=\".\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"s[path]\", size=15)\n",
    "ax.set_ylabel(\"F (kT)\", size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f6e13e-0160-44e3-ba57-81606bc7c12a",
   "metadata": {},
   "source": [
    "### Study convergence of the FES as function of path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4dad3d-93e7-423d-b46b-4c44dd676f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "calculate = True\n",
    "n_swarms = 36\n",
    "n_beads = 18\n",
    "step = 50\n",
    "step = step * n_swarms * n_beads\n",
    "\n",
    "FES_vs_t = []\n",
    "FES_vs_t.append(np.linspace(extent[0], extent[1], nbins))\n",
    "for i in tqdm(range(step, s_path.shape[0]+step,step)):\n",
    "    s = s_path[: i , :, :]\n",
    "    c = cv_coordinates[: i, :, :]\n",
    "    t = my_msm.cvs_to_tica(c, drop=[20, 21, 22, 23, 32, 33, 34, 35]) \n",
    "    cl = my_msm.k_means_cluster(t, k, stride=1, max_iter=500, n_jobs=4, seed=28101990)\n",
    "    try:\n",
    "        _, w= my_msm.get_msm(cl, n_jobs=4)\n",
    "    except:\n",
    "        continue\n",
    "    p_of_cv, extent = my_msm.get_kde(\n",
    "        s,\n",
    "        w,\n",
    "        bandwidth,\n",
    "        nbins=nbins,\n",
    "    )\n",
    "    f0 = -np.log(p_of_cv)\n",
    "    f = f0 - f0.min()\n",
    "    f[f > 40] = np.nan\n",
    "    FES_vs_t.append(f)\n",
    "FES_vs_t.append(f)\n",
    "FES_vs_t = np.array(FES_vs_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024c11cb-9fc9-4ce6-a4e8-8b73e294677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = spc.plot_FES_1d_vs_t(FES_vs_t, xlabel=\"s[path] (nm)\", error=error)\n",
    "ax.set_ylim([0, 25])\n",
    "ax.set_xlim([0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf66218-34f4-45e3-bf87-3f36813aaeda",
   "metadata": {},
   "source": [
    "## FES s-path vs property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0e7634-bde6-4bed-a50a-1d549559cdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_path = cvs_path[:, :, 0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aede5a35-e8da-4db2-b1c5-6649155d0e80",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Path vs SF (checks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fca44fa-f242-439b-861f-73f1032381cb",
   "metadata": {},
   "source": [
    "It is interesting to have a 2D FES of the path cv vs another cv to see at which point in the transition the other cv changes. \n",
    "\n",
    "This is very easy to do with this code just prepare the other_cv array with the correct shape in the variable `other_cv`. In this case, I am doing some averaging which is usefull for KcsA but it can be anything really."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03c330b-8ae2-48fa-a02f-ffb8b3264c76",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8e9a88-cbe6-4efd-9dda-f71e2e10248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_cv_id = [0, 1]\n",
    "cv_name = \"SF\"\n",
    "cv_fig_label = \"SF (nm)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dadfe6a-c21a-4329-9425-d3cee7d9e447",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_cv = my_cvs.average_strings_to_cv(cv_coordinates, other_cv_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b346378-87ce-4c59-9cc7-2ad90700813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = np.concatenate([s_path, other_cv], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1edceb-c98a-4e87-b66b-85d1cce54935",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bandwidth = 0.05\n",
    "p_of_cv, extent = my_msm.get_kde(cvs, weights, bandwidth)\n",
    "F0 = -np.log(p_of_cv)\n",
    "F = F0 - F0.min()\n",
    "F[F > 40] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca13125-e14e-4790-b93d-15fa8513b491",
   "metadata": {},
   "source": [
    "Do the projection and take log. You have to choose a bandwidth for the [KDE](https://en.wikipedia.org/wiki/Kernel_density_estimation) of the histogram. It should be big enough to reduce noise but not so big to remove features. If you give `None`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1482dd-29db-4ecb-8da3-e83cb5ccfd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = my_plot.plot_2D_heatmap(\n",
    "    F,\n",
    "    extent,\n",
    "    f_max=25,\n",
    "    f_min=0,\n",
    "    cbar_label=\"Free Energy (kT)\",\n",
    "    xlabel=\"s[path]\",\n",
    "    ylabel=cv_fig_label,\n",
    ")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0d3a36-cd02-4bd6-aa3a-b13f6c7534a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6e33c9-0df6-45f5-a181-3ca5aa5a3726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "string_sims_analysis",
   "language": "python",
   "name": "string_sims_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
