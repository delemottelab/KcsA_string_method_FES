{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String Simulation Analysis\n",
    "\n",
    "This notebook will help you analyse the convergence of the string-method and if you are lucky extract a nice free energy surface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "from math import ceil\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter, AutoMinorLocator\n",
    "from MDAnalysis.analysis.align import AlignTraj\n",
    "import MDAnalysis as mda\n",
    "import nglview as nv\n",
    "import pickle\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import pyemma\n",
    "\n",
    "logging.getLogger(\"matplotlib\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"blib2to3.pgen2.driver\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"pyemma\").setLevel(logging.NOTSET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorbar(mappable, cmap, norm, label0, size=10):\n",
    "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "    ax = mappable.axes\n",
    "    fig = ax.figure\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar = mpl.colorbar.ColorbarBase(cax, cmap=cmap, norm=norm)\n",
    "    cbar.set_label(label0, size=size)\n",
    "    return cbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"axes.facecolor\"] = \"#f9f9fb\"\n",
    "plt.rcParams[\"grid.color\"] = \"white\"\n",
    "plt.rcParams[\"grid.linestyle\"] = \"-\"\n",
    "plt.rcParams[\"grid.linewidth\"] = 2\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "plt.rcParams[\"lines.solid_capstyle\"] = \"round\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def natural_sort(l):\n",
    "    \"\"\"\n",
    "    Takes as input a list l of strings and sorts it with natural order.\n",
    "      Parameters\n",
    "      ----------\n",
    "      l: list of strings.\n",
    "      Returns\n",
    "      -------\n",
    "      l sorted\n",
    "    \"\"\"\n",
    "    from re import split\n",
    "\n",
    "    assert isinstance(l, list), \"l is not a list!\"\n",
    "    for i in l:\n",
    "        assert isinstance(i, str), \"List contains non-string elements.\"\n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [convert(c) for c in split(\"([0-9]+)\", key)]\n",
    "    return sorted(l, key=alphanum_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String Convergence Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract CVs\n",
    "\n",
    "In the cell bellow you can select which will be the simulation directory (in case this notebook is elsewhere). If the notebook is in the simulation directory just leave it as \".\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls ../data/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_directory = \"/data/sperez/Projects/string_sims/data/raw/C2I_v1/\"\n",
    "simulation_directory = \"/data/sperez/Projects/string_sims/data/raw/C2I_lb_v2/\"\n",
    "simulation_directory = \"/data/sperez/Projects/string_sims/data/raw/C2I_lb_v1/\"\n",
    "os.chdir(simulation_directory)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the strings in the `strings` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = natural_sort(glob.glob(\"./strings/string[0-9]*txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = np.array([np.loadtxt(file).T for file in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cv.pkl\", \"rb\") as file:\n",
    "    cvs, ndx_groups = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"String details\")\n",
    "print(\"\")\n",
    "print(f\"Number of string: {strings.shape[0]}\")\n",
    "print(f\"Number of cvs: {strings.shape[1]}\")\n",
    "print(f\"Number of beads per string: {strings.shape[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze string convergence\n",
    "In these next plots you will be able to study the convergence of the string. At convergence the strings should be oscillating around an equilibrium position and not drift over the different iterations.\n",
    "\n",
    "## Strings as a function of time\n",
    "In this plot we can see the evolution of each string CV as function of the timeration number separatelly.\n",
    "\n",
    "You can change two parameters in these plots the `start_iteration` before which all data is not plotted and the `n_average` which is the number of strings iterations to average in one block of strings. This is done in order to cancel some of the noisyness in the representation, to reduce the number of strings in the plot and to see more clearly if there is average drift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ borrar Ãºltimo string\n",
    "+ probar con el GPCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_iteration = 0\n",
    "n_average = 20\n",
    "\n",
    "\n",
    "n_plots = strings.shape[1]\n",
    "n_strings = strings.shape[0]\n",
    "fig, ax = plt.subplots(ceil(n_plots / 2), 2, figsize=(20, 8 * ceil(n_plots / 2)))\n",
    "ax = ax.flatten()\n",
    "cmap = plt.cm.viridis_r\n",
    "n_colors = (n_strings - start_iteration) // n_average + 1\n",
    "colors = cmap(np.linspace(0, 1, n_colors))  # yellow to blue\n",
    "norm = mpl.colors.Normalize(vmin=start_iteration, vmax=n_strings - 1)\n",
    "\n",
    "for i, a in enumerate(ax[:n_plots]):\n",
    "    a.plot(strings[0, i, :], ls=\":\", marker=\".\", label=\"string0\", color=\"r\")\n",
    "    for jj, j in enumerate(range(start_iteration, n_strings, n_average)):\n",
    "        string = np.mean(strings[j : j + n_average, i, :], axis=0)\n",
    "        a.plot(string, ls=\"-\", marker=\"o\", color=colors[jj])\n",
    "    av = np.mean(strings[start_iteration:, i, :], axis=0)\n",
    "    std = np.std(strings[start_iteration:, i, :], axis=0)\n",
    "    #    a.fill_between(\n",
    "    #        np.arange(len(av)),\n",
    "    #        av + std,\n",
    "    #        av - std,\n",
    "    #        alpha=0.4,\n",
    "    #        label=f\"std(string{start_iteration}-{n_strings})\",\n",
    "    #    )\n",
    "    #    a.plot(\n",
    "    #        av,\n",
    "    #        ls=\"-\",\n",
    "    #        marker=\".\",\n",
    "    #        color=\"k\",\n",
    "    #        label=f\"mean(string{start_iteration}-{n_strings})\",\n",
    "    #    )\n",
    "    a.set_ylabel(\n",
    "        f\"{list(ndx_groups.keys())[2*i]} - {list(ndx_groups.keys())[2*i+1]} (nm)\",\n",
    "        size=18,\n",
    "        labelpad=16,\n",
    "    )\n",
    "    a.set_xlabel(\"bead number\", size=15, labelpad=13)\n",
    "    a.set_xlim(left=0, right=strings.shape[2] - 1)\n",
    "    a.xaxis.set_minor_locator(MultipleLocator(1))\n",
    "    a.xaxis.set_major_locator(MultipleLocator(1))\n",
    "    a.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    a.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "    a.grid(which=\"minor\")\n",
    "    a.tick_params(axis=\"y\", labelsize=14)\n",
    "    a.tick_params(axis=\"x\", labelsize=11)\n",
    "    a.set_title(f\"cv{i}\")\n",
    "    if i % 2 != 0:\n",
    "        a.legend()\n",
    "        cbar = colorbar(a, cmap, norm, \"iteration number\", 20)\n",
    "if n_plots % 2:\n",
    "    fig.delaxes(ax[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_plots = strings.shape[1]\n",
    "n_strings = strings.shape[0]\n",
    "fig, ax = plt.subplots(ceil(n_plots / 2), 2, figsize=(20, 8 * ceil(n_plots / 2)))\n",
    "ax = ax.flatten()\n",
    "for i, a in enumerate(ax[:n_plots]):\n",
    "    x = np.arange(n_strings)\n",
    "    y = strings[:, i, :] - strings[0, i, :]\n",
    "    y = np.sqrt(np.sum(y * y, axis=1) / strings.shape[2])\n",
    "    a.plot(x, y)\n",
    "\n",
    "    a.set_ylabel(\n",
    "        f\"RMSD[{list(ndx_groups.keys())[2*i]} - {list(ndx_groups.keys())[2*i+1]} (nm)]\",\n",
    "        size=18,\n",
    "        labelpad=16,\n",
    "    )\n",
    "    a.set_xlabel(\"iteration number\", size=15, labelpad=13)\n",
    "    a.set_title(f\"cv{i}\")\n",
    "if n_plots % 2:\n",
    "    fig.delaxes(ax[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution over CVs that are a function of the cvs\n",
    "\n",
    "If you are interested in studying the convergence of cvs that are a function of CVs (for example averaging over symmetrical distances). You can construct a `reduced_string` array in which cvs are a function of the cvs used for the string method. In the example bellow, we produce two cvs which are the mean of cvs used in the string method simulation. Then, similar plotting as before can be done. \n",
    "\n",
    "In addition if you are interested in the convergence of some other cv which is not a function of the cvs used in the string method you can also study them! Just extract the average value of that particular CV in the `md/*/*/restrained/traj_comp.xtc` for all the restrained simulation and shape them into an `reduced_string` numpy array with shape (n_iterations, n_cvs, n_beads).\n",
    "\n",
    "If this sort of analysis is meaningless in your system, for example because the chosen cvs are very diagnostic, please ignore this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reduced_string = np.hstack(\n",
    "    [\n",
    "        np.mean(strings[:, 0:2, :], axis=1, keepdims=True),\n",
    "        np.mean(strings[:, 10:12, :], axis=1, keepdims=True),\n",
    "    ]\n",
    ")\n",
    "reduced_string_labels = [\"SF (nm)\", \"IG (nm)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_iteration = 100\n",
    "n_average = 10\n",
    "\n",
    "n_strings = strings.shape[0]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 7))\n",
    "cmap = plt.cm.viridis_r\n",
    "n_colors = (n_strings - start_iteration) // n_average + 1\n",
    "colors = cmap(np.linspace(0, 1, n_colors))  # yellow to blue\n",
    "norm = mpl.colors.Normalize(vmin=start_iteration, vmax=n_strings - 1)\n",
    "ax.plot(\n",
    "    reduced_string[0, 0, :],\n",
    "    reduced_string[0, 1, :],\n",
    "    ls=\":\",\n",
    "    marker=\".\",\n",
    "    label=\"string0\",\n",
    "    color=\"k\",\n",
    ")\n",
    "av_0 = np.mean(reduced_string[start_iteration:, 0, :], axis=0)\n",
    "std_0 = np.std(reduced_string[start_iteration:, 0, :], axis=0)\n",
    "av_1 = np.mean(reduced_string[start_iteration:, 1, :], axis=0)\n",
    "std_1 = np.std(reduced_string[start_iteration:, 1, :], axis=0)\n",
    "ax.plot(\n",
    "    av_0,\n",
    "    av_1,\n",
    "    ls=\"-\",\n",
    "    marker=\".\",\n",
    "    color=\"k\",\n",
    "    label=f\"mean(string{start_iteration}-{n_strings})\",\n",
    ")\n",
    "\n",
    "for jj, j in enumerate(range(start_iteration, n_strings, n_average)):\n",
    "    av_0 = np.mean(reduced_string[j:, 0, :], axis=0)\n",
    "    std_0 = np.std(reduced_string[j:, 0, :], axis=0)\n",
    "    av_1 = np.mean(reduced_string[j:, 1, :], axis=0)\n",
    "    std_1 = np.std(reduced_string[j:, 1, :], axis=0)\n",
    "    ax.errorbar(\n",
    "        av_0, av_1, fmt=\"--\", xerr=std_0, yerr=std_1, color=colors[jj], alpha=0.9\n",
    "    )\n",
    "\n",
    "\n",
    "ax.set_ylabel(\n",
    "    reduced_string_labels[1],\n",
    "    size=18,\n",
    "    labelpad=16,\n",
    ")\n",
    "ax.set_xlabel(\n",
    "    reduced_string_labels[0],\n",
    "    size=18,\n",
    "    labelpad=16,\n",
    ")\n",
    "\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "ax.xaxis.set_major_locator(MultipleLocator(0.1))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "ax.grid(which=\"minor\")\n",
    "ax.tick_params(axis=\"y\", labelsize=14)\n",
    "ax.tick_params(axis=\"x\", labelsize=11)\n",
    "ax.legend()\n",
    "cbar = colorbar(ax, cmap, norm, \"iteration number\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_strings = reduced_string.shape[0]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "x = np.arange(n_strings)\n",
    "y = reduced_string[:, :, :] - reduced_string[0, :, :]\n",
    "y = np.sqrt(np.sum(y * y, axis=(1, 2)) / strings.shape[2])\n",
    "ax.plot(x, y)\n",
    "ax.set_ylabel(\n",
    "    f\"RMSD[Reduced string (nm)]\",\n",
    "    size=18,\n",
    "    labelpad=16,\n",
    ")\n",
    "ax.set_xlabel(\"iteration number\", size=15, labelpad=13)\n",
    "ax.set_title(f\"RMSD[Reduced string]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New CVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum of CVs cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_cv(cv):\n",
    "    cv = (cv - cv.min()) / (cv.max() - cv.min())\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = (\n",
    "    0.5 * scale_cv(strings[:, 11:12, :])\n",
    "    + 0.5 * scale_cv(strings[:, 10:11, :])\n",
    "    - 0.5 * scale_cv(strings[:, 0:1, :])\n",
    "    - 0.5 * scale_cv(strings[:, 1:2, :])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_iteration = 0\n",
    "n_average = 20\n",
    "\n",
    "n_strings = cv.shape[0]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 8))\n",
    "cmap = plt.cm.viridis_r\n",
    "n_colors = (n_strings - start_iteration) // n_average + 1\n",
    "colors = cmap(np.linspace(0, 1, n_colors))  # yellow to blue\n",
    "norm = mpl.colors.Normalize(vmin=start_iteration, vmax=n_strings - 1)\n",
    "\n",
    "ax.plot(cv[-1, 0, :], ls=\":\", marker=\".\", label=\"string0\", color=\"r\")\n",
    "for jj, j in enumerate(range(start_iteration, n_strings, n_average)):\n",
    "    string = np.mean(cv[j : j + n_average, 0, :], axis=0)\n",
    "    ax.plot(string, ls=\"-\", marker=\"o\", color=colors[jj])\n",
    "av = np.mean(cv[start_iteration:, 0, :], axis=0)\n",
    "std = np.std(cv[start_iteration:, 0, :], axis=0)\n",
    "#    a.fill_between(\n",
    "#        np.arange(len(av)),\n",
    "#        av + std,\n",
    "#        av - std,\n",
    "#        alpha=0.4,\n",
    "#        label=f\"std(string{start_iteration}-{n_strings})\",\n",
    "#    )\n",
    "#    a.plot(\n",
    "#        av,\n",
    "#        ls=\"-\",\n",
    "#        marker=\".\",\n",
    "#        color=\"k\",\n",
    "#        label=f\"mean(string{start_iteration}-{n_strings})\",\n",
    "#    )\n",
    "ax.set_ylabel(\n",
    "    f\"Two-gate cv\",\n",
    "    size=18,\n",
    "    labelpad=16,\n",
    ")\n",
    "ax.set_xlabel(\"bead number\", size=15, labelpad=13)\n",
    "ax.set_xlim(left=0, right=strings.shape[2] - 1)\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(1))\n",
    "ax.xaxis.set_major_locator(MultipleLocator(1))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "ax.grid(which=\"minor\")\n",
    "ax.tick_params(axis=\"y\", labelsize=14)\n",
    "ax.tick_params(axis=\"x\", labelsize=11)\n",
    "ax.set_title(f\"Two-gate cv\")\n",
    "if i % 2 != 0:\n",
    "    a.legend()\n",
    "    cbar = colorbar(a, cmap, norm, \"iteration number\", 20)\n",
    "if n_plots % 2:\n",
    "    fig.delaxes(ax[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free Energy Surface\n",
    "\n",
    "Once your strings are converged, the swarms are sampling over and over the same part of phase space and we can discretrize it and do statistics on the jumps. This will result in a free energy surface along some cv, which may not need to be the ones that parametrize the string. It is very important to keep in mind that a converged string does not imply a converged FES and it might be necessary to do one or two (or more) hundred additional iterations.\n",
    "\n",
    "\n",
    "Now instead of using the data in `strings/string*.xtx` we will use the data in `md/*/*/s*/pullx.xvg` if we want to use the cvs of the string. Otherwise, you add here code that reads `md/*/*/s*/traj_comp.xtc`, calculates your desired cv and then shapes the data into the correct shape `(n_iterations*n_swarms_per_iter*n_beads, n_frames_per_iter, n_cvs)`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The path of `sys.path.append` should lead to the library `string-method-gmxapi`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../../../string-method-gmxapi\")\n",
    "from stringmethod.config import *\n",
    "from stringmethod.postprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_swarm_data(extract, first_iteration=1, last_iteration=None):\n",
    "    if last_iteration == None:\n",
    "        last_iteration = sys.maxsize\n",
    "    if extract:\n",
    "        config = load_config(\"config.json\")\n",
    "\n",
    "        ce = CvValueExtractor.from_config(\n",
    "            config=config,\n",
    "            first_iteration=first_iteration,  # Exclude the first iterations to let the system equilibrate.\n",
    "            last_iteration=last_iteration,  # Usefull to make blocks of the simulation\n",
    "        )\n",
    "        ce.run()\n",
    "        ce.persist()\n",
    "    return np.load(\"postprocessing/cv_coordinates.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_fes(\n",
    "    grid,\n",
    "    free_energy,\n",
    "    fe_cut_off=None,\n",
    "    cv_labels=[\"cv0 (nm)\", \"cv1 (nm)\"],\n",
    "    cbar_label=\"Free Energy (kT)\",\n",
    "    ax=None,\n",
    "    fig=None,\n",
    "    f_min=None,\n",
    "    f_max=None,\n",
    "):\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "    if fe_cut_off == None:\n",
    "        fe_cut_off = sys.maxsize\n",
    "    free_energy[free_energy > fe_cut_off] = np.nan\n",
    "    cv_0 = grid[:, 0]\n",
    "    if free_energy.shape[1] == 1:\n",
    "        ax.plot(cv_0, free_energy, \"--o\")\n",
    "        ax.set_ylabel(\"Free Energy (kT)\")\n",
    "    else:\n",
    "        cv_1 = grid[:, 1]\n",
    "        n_colors = 50\n",
    "        im = ax.contourf(\n",
    "            cv_0,\n",
    "            cv_1,\n",
    "            free_energy.T,\n",
    "            levels=n_colors,\n",
    "            # norm=mpl.colors.PowerNorm(gamma=-1 / 3),\n",
    "            cmap=plt.cm.RdYlBu_r,\n",
    "            vmin=f_min,\n",
    "            vmax=f_max,\n",
    "        )\n",
    "        if f_min is None:\n",
    "            f_min = np.nanmin(free_energy)\n",
    "        if f_max is None:\n",
    "            f_max = np.nanmax(free_energy)\n",
    "        cmap = plt.cm.RdYlBu_r\n",
    "        colors = cmap(np.linspace(0, 1, n_colors))  # yellow to blue\n",
    "        norm = mpl.colors.Normalize(vmin=f_min, vmax=f_max)\n",
    "        cbar = colorbar(ax, cmap, norm, cbar_label, 20)\n",
    "        ax.set_ylabel(cv_labels[1])\n",
    "        # ax.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "        # ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "    ax.set_xlabel(cv_labels[0])\n",
    "    # ax.xaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    # ax.xaxis.set_major_locator(MultipleLocator(0.1))\n",
    "    if fig is not None:\n",
    "        fig.tight_layout()\n",
    "        return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_transition_matrix(\n",
    "    cv_coordinates,\n",
    "    n_grid_points=15,\n",
    "    T=300,\n",
    "    kB=0.001987204,\n",
    "    convergence_cutoff=1.0e-8,\n",
    "    method=\"eigenvector\",\n",
    "    symm=False,\n",
    "):\n",
    "    config = load_config(\"config.json\")\n",
    "    tc = TransitionCountCalculator.from_config(\n",
    "        config=config,\n",
    "        # You probably want to play around with n_grid_points.\n",
    "        # It sets the resolution. Its optimal value depends on your swarm trajectory length and sample size\n",
    "        n_grid_points=n_grid_points,\n",
    "        cv_coordinates=cv_coordinates,\n",
    "    )\n",
    "    tc.run()\n",
    "    tc.persist()\n",
    "    if symm:\n",
    "        tc.transition_count = 0.5 * (tc.transition_count + tc.transition_count)\n",
    "        print(\"symmetrize!\")\n",
    "    fc = FreeEnergyCalculator.from_config(\n",
    "        config=config,\n",
    "        grid=tc.grid,\n",
    "        transition_count=tc.transition_count,\n",
    "        T=T,\n",
    "        kB=kB,\n",
    "        method=method,\n",
    "        convergence_cutoff=convergence_cutoff,\n",
    "    )\n",
    "    fc.run()\n",
    "    fc.persist()\n",
    "    return tc.grid, fc.free_energy, tc.transition_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `load_swarm_data` function will load the swarm data in the `cv_coordinates`. If you set `extract=True` it will read the data from the swarm files. If you have done this previously you can set `extract=False` so the function just reads `postprocessing/cv_coordinates.npy`. `first_iteration` can be used to exclude initial swarms as equilibration and `last_iteration` can be done to exclude some iterations for example if you want to estimate the FES convergence by comparing blocks of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls md/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%rm -r md/277/\n",
    "#%rm postprocessing/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv_coordinates = load_swarm_data(extract=True, first_iteration=100, last_iteration=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ You can do some function of the cvs, like the mean of several:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv_coordinates_clean = np.concatenate(\n",
    "    [\n",
    "        np.concatenate([cv_coordinates[:, :, 0:1], cv_coordinates[:, :, 1:2]], axis=0),\n",
    "        np.concatenate(\n",
    "            [cv_coordinates[:, :, 10:11], cv_coordinates[:, :, 11:12]], axis=0\n",
    "        ),\n",
    "    ],\n",
    "    axis=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv_coordinates_clean = np.concatenate(\n",
    "    [\n",
    "        np.mean([cv_coordinates[:, :, 0:1], cv_coordinates[:, :, 1:2]], axis=0),\n",
    "        np.mean([cv_coordinates[:, :, 10:11], cv_coordinates[:, :, 11:12]], axis=0),\n",
    "    ],\n",
    "    axis=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_coordinates_clean = (\n",
    "    0.5 * scale_cv(cv_coordinates[:, :, 10:11])\n",
    "    + 0.5 * scale_cv(cv_coordinates[:, :, 11:12])\n",
    "    - 0.5 * scale_cv(cv_coordinates[:, :, 0:1])\n",
    "    - 0.5 * scale_cv(cv_coordinates[:, :, 1:2])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_variable(path, vec, lam=None):\n",
    "    from numpy.linalg import norm\n",
    "\n",
    "    n_beads = path.shape[1]\n",
    "\n",
    "    if lam is None:\n",
    "        lam = (\n",
    "            2.3\n",
    "            * (n_beads - 1)\n",
    "            / np.sum([norm(path[:, i] - path[:, i + 1]) for i in range(1, n_beads - 1)])\n",
    "        )\n",
    "\n",
    "    array = np.array(\n",
    "        [np.exp(-lam * norm(vec - bead)) for i, bead in enumerate(path[:, 1:].T)]\n",
    "    )\n",
    "\n",
    "    s = np.sum(np.arange(0, n_beads - 1) * array) / np.sum(array) / (n_beads - 1)\n",
    "    return s, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = None\n",
    "lam = 1 / 2\n",
    "cv_coordinates_clean = np.zeros((cv_coordinates.shape[0], cv_coordinates.shape[1], 1))\n",
    "cv = np.zeros(\n",
    "    (cv_coordinates.shape[0], cv_coordinates.shape[1], cv_coordinates.shape[2])\n",
    ")\n",
    "for i in range(cv_coordinates.shape[2]):\n",
    "    cv[:, :, i : i + 1] = cv_coordinates[:, :, i : i + 1]\n",
    "    cv[:, :, i : i + 1] = cv_coordinates[:, :, i : i + 1]\n",
    "\n",
    "path = strings[-1, :, :]\n",
    "for i in range(cv.shape[0]):\n",
    "    for j in range(cv.shape[1]):\n",
    "        s, lam = get_path_variable(path, cv[i, j, :], lam)\n",
    "        cv_coordinates_clean[i, j, 0] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1 / lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cv_coordinates_clean.reshape(cv_coordinates_clean.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ You can of course make your own function that extracts cvs from the trajectory and makes a cv_coordinates_clean with the correct shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the above cells only run the one you are more interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This functions takes the `cv_coordinates_clean` numpy array and calculates a transition matrix by doing a simple grid on the cv space. It also calculates the probability of transition using the master equation and this results in the calculation of a FES. `n_grid_points` choose the number of grid points of the grid, the coarse the grid the more detailed (and noisy) the FES. This parameter should be varied to obtain an acceptable signal-to-noise ration. The temperature `T` and the value of `kB` can be set too. `kB` is used to give units to the FES. In this example we will use \"kBT\" units since kBT=1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function bellow takes the `grid` and `free_energy` arrays from the previous step and plots the free energy surface. The function returns the matplotlib `fig` and `ax` for you to format further if you want. `fe_cut_off` is a maximum value of free energy overwhich nothing is plotted and `cv_labels` are the labels of the cvs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_max = strings.shape[0]\n",
    "n_skip = 25\n",
    "n_start = 100\n",
    "n_swarms = 32\n",
    "n_beads = 16\n",
    "n_axes = (n_max - n_start) // n_skip + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 7 * 1))\n",
    "grid, free_energy, tc = calculate_transition_matrix(\n",
    "    cv_coordinates_clean[\n",
    "        :,\n",
    "        :,\n",
    "        :,\n",
    "    ],\n",
    "    n_grid_points=30,\n",
    "    T=1,\n",
    "    kB=1,\n",
    "    method=\"eigenvector\",\n",
    "    convergence_cutoff=1.0e-10,\n",
    ")\n",
    "show_fes(\n",
    "    grid,\n",
    "    free_energy,\n",
    "    # fe_cut_off=50.0,\n",
    "    cv_labels=[\"SF (nm)\", \"IG (nm)\"],\n",
    "    cbar_label=\"Free Energy (kT)\",\n",
    "    ax=ax,\n",
    "    f_min=0,\n",
    "    f_max=20,\n",
    ")\n",
    "ax.grid(b=None)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cvs(cv_coordinates_clean, value):\n",
    "    a = np.where(\n",
    "        cv_coordinates_clean\n",
    "        == cv_coordinates_clean.flat[np.abs(cv_coordinates_clean - value).argmin()]\n",
    "    )\n",
    "    return a[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_coordinates[get_cvs(cv_coordinates_clean, -0.4), 1, [0, 1, 10, 11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_coordinates[get_cvs(cv_coordinates_clean, -0.6), 1, [0, 1, 10, 11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_coordinates[get_cvs(cv_coordinates_clean, 0.2), 1, [0, 1, 10, 11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_coordinates[get_cvs(cv_coordinates_clean, 0.5), 1, [0, 1, 10, 11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(n_axes, 1, figsize=(10, 7 * n_axes))\n",
    "ax = ax.flatten()\n",
    "for i in range(n_axes):\n",
    "    grid, free_energy, tc = calculate_transition_matrix(\n",
    "        cv_coordinates_clean[\n",
    "            n_start : n_start + (i + 1) * n_skip * n_swarms * n_beads,\n",
    "            :,\n",
    "            :,\n",
    "        ],\n",
    "        n_grid_points=40,\n",
    "        T=1,\n",
    "        kB=1,\n",
    "        convergence_cutoff=1.0e-8,\n",
    "    )\n",
    "    show_fes(\n",
    "        grid,\n",
    "        free_energy,\n",
    "        fe_cut_off=100.0,\n",
    "        cv_labels=[\"SF (nm)\", \"IG (nm)\"],\n",
    "        cbar_label=\"Free Energy (kT)\",\n",
    "        ax=ax[i],\n",
    "        f_min=0,\n",
    "        f_max=15,\n",
    "    )\n",
    "    ax[i].grid(b=None)\n",
    "\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_msm(cv0, n_grid):\n",
    "    cv = cv0.copy()\n",
    "    trj_concat = cv.reshape(cv.shape[0] * 2, cv.shape[2]).copy()\n",
    "    cv[:, :, 0] -= cv[:, :, 0].min()\n",
    "    cv[:, :, 1] -= cv[:, :, 1].min()\n",
    "    dx = cv[:, :, 0].max() / n_grid\n",
    "    dy = cv[:, :, 1].max() / n_grid\n",
    "    cv[:, :, 0] = cv[:, :, 0] // dx\n",
    "    cv[:, :, 1] = cv[:, :, 1] // dy\n",
    "\n",
    "    state_traj = []\n",
    "    for k in range(0, cv.shape[0]):\n",
    "        state0 = cv[k, 0, 1] * n_grid + cv[k, 0, 0]\n",
    "        state1 = cv[k, 1, 1] * n_grid + cv[k, 1, 0]\n",
    "        state_traj.append(np.array([state0, state1], dtype=int))\n",
    "\n",
    "    msm = pyemma.msm.bayesian_markov_model(\n",
    "        state_traj,\n",
    "        lag=1,\n",
    "        dt_traj=\"0.01 ns\",\n",
    "        reversible=False,\n",
    "    )\n",
    "    print(\"fraction of states used = {:.2f}\".format(msm.active_state_fraction))\n",
    "    print(\"fraction of counts used = {:.2f}\".format(msm.active_count_fraction))\n",
    "    return trj_concat, msm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grid = 20\n",
    "trj_concat, msm = make_msm(cv_coordinates_clean, n_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(10, 8), sharex=True, sharey=True)\n",
    "pyemma.plots.plot_free_energy(\n",
    "    *trj_concat.T,\n",
    "    weights=np.concatenate(msm.trajectory_weights()),\n",
    "    ax=axes,\n",
    "    nbins=50,\n",
    "    legacy=False,\n",
    "    cmap=\"RdYlBu_r\",\n",
    "    # ncontours=45,\n",
    "    kt=1,\n",
    "    # vmax=10,\n",
    "    cbar_label=\"free energy (kcal/mol)\"\n",
    ")\n",
    "axes.grid(b=None)\n",
    "axes.set_xlabel(\"SF (nm)\")\n",
    "axes.set_ylabel(\"IG (nm)\")\n",
    "axes.set_title(\"Reweighted free energy surface\", fontweight=\"bold\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(f\"./free_energy2.svg\", transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InfleCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/sperez/Projects/InfleCS\")\n",
    "import free_energy_clustering as FEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0 = cv_coordinates_clean[:, 0, :]\n",
    "data_1 = cv_coordinates_clean[:, 1, :]\n",
    "data = np.concatenate((data_0, data_1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fec = FEC.FreeEnergyClustering(\n",
    "    data,\n",
    "    min_n_components=1,\n",
    "    max_n_components=20,\n",
    "    temperature=290.0,\n",
    "    n_iterations=5,\n",
    "    n_grids=80,\n",
    "    n_splits=1,\n",
    "    stack_landscapes=False,\n",
    "    data_weights=np.concatenate(msm.trajectory_weights()),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coords, FE_landscape, FE_points = fec.landscape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_iteration = 1\n",
    "n_average = 1\n",
    "\n",
    "n_strings = strings.shape[0]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 7))\n",
    "cmap = plt.cm.viridis_r\n",
    "n_colors = (n_strings - start_iteration) // n_average + 1\n",
    "colors = cmap(np.linspace(0, 1, n_colors))  # yellow to blue\n",
    "norm = mpl.colors.Normalize(vmin=start_iteration, vmax=n_strings - 1)\n",
    "ax.plot(\n",
    "    reduced_string[0, 0, :],\n",
    "    reduced_string[0, 1, :],\n",
    "    ls=\":\",\n",
    "    marker=\".\",\n",
    "    label=\"string0\",\n",
    "    color=\"k\",\n",
    ")\n",
    "av_0 = np.mean(reduced_string[start_iteration:, 0, :], axis=0)\n",
    "std_0 = np.std(reduced_string[start_iteration:, 0, :], axis=0)\n",
    "av_1 = np.mean(reduced_string[start_iteration:, 1, :], axis=0)\n",
    "std_1 = np.std(reduced_string[start_iteration:, 1, :], axis=0)\n",
    "ax.plot(\n",
    "    av_0,\n",
    "    av_1,\n",
    "    ls=\"-\",\n",
    "    marker=\".\",\n",
    "    color=\"k\",\n",
    "    # label=f\"mean(string{start_iteration}-{n_strings})\",\n",
    ")\n",
    "\n",
    "for jj, j in enumerate(range(start_iteration, n_strings, n_average)):\n",
    "    av_0 = np.mean(reduced_string[j:, 0, :], axis=0)\n",
    "    std_0 = np.std(reduced_string[j:, 0, :], axis=0)\n",
    "    av_1 = np.mean(reduced_string[j:, 1, :], axis=0)\n",
    "    std_1 = np.std(reduced_string[j:, 1, :], axis=0)\n",
    "    ax.errorbar(\n",
    "        av_0, av_1, fmt=\"--\", xerr=std_0, yerr=std_1, color=colors[jj], alpha=0.9\n",
    "    )\n",
    "\n",
    "\n",
    "ax.set_ylabel(\n",
    "    reduced_string_labels[1],\n",
    "    size=18,\n",
    "    labelpad=16,\n",
    ")\n",
    "ax.set_xlabel(\n",
    "    reduced_string_labels[0],\n",
    "    size=18,\n",
    "    labelpad=16,\n",
    ")\n",
    "\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "ax.xaxis.set_major_locator(MultipleLocator(0.1))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "ax.grid(which=\"minor\")\n",
    "ax.tick_params(axis=\"y\", labelsize=14)\n",
    "ax.tick_params(axis=\"x\", labelsize=11)\n",
    "ax.legend()\n",
    "fec.visualize(\n",
    "    savefig=False,\n",
    "    show_data=False,\n",
    "    # vmax=3.,\n",
    "    n_contour_levels=25,\n",
    "    ylabel=\"IG (nm)\",\n",
    "    xlabel=\"SF (nm)\",\n",
    "    filename=\"free_energy_landscape\",\n",
    "    title=\"Free energy landscape\",\n",
    "    ax=ax,\n",
    ")\n",
    "# cbar = colorbar(ax, cmap, norm, \"iteration number\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fec.visualize(\n",
    "    savefig=False,\n",
    "    show_data=False,\n",
    "    # vmax=3.,\n",
    "    n_contour_levels=100,\n",
    "    ylabel=\"IG (nm)\",\n",
    "    xlabel=\"SF (nm)\",\n",
    "    filename=\"free_energy_landscape\",\n",
    "    title=\"Free energy landscape\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "string_method",
   "language": "python",
   "name": "string_method"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-showcode": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
